{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "943ac22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.openvla_oft.configuration_prismatic import OpenVLAConfig\n",
    "from models.openvla_oft.modeling_prismatic import OpenVLAForActionPrediction\n",
    "from models.openvla_oft.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "# from models.openvla_oft.openvla_utils import update_auto_map, check_model_logic_mismatch\n",
    "from transformers import AutoConfig, AutoImageProcessor, AutoModelForVision2Seq, AutoProcessor\n",
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoImageProcessor.register(OpenVLAConfig, PrismaticImageProcessor)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "AutoModelForVision2Seq.register(OpenVLAConfig, OpenVLAForActionPrediction)\n",
    "# local_path = \"/file_system/common-models/SimpleVLA-RL/Openvla-oft-SFT-libero10-trajall\"\n",
    "# local_path = \"/file_system/common-models/SimpleVLA-RL/Openvla-oft-SFT-libero10-trajall\"\n",
    "# local_path = \"/file_system/common-models/Haozhan72-kangsheng/Openvla-oft-SFT-libero10-trajall/\"\n",
    "# local_path = \"/file_system/common-models/Haozhan72-kangsheng/Openvla-oft-SFT-libero10-traj1/\"\n",
    "local_path = \"/file_system/kangsheng/verl/checkpoints/simple-vla-all-sft/merge/\"\n",
    "# if self.rank == 0:\n",
    "#update_auto_map(local_path)\n",
    "#check_model_logic_mismatch(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cd0ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********USE VLA tokenizer*************\n"
     ]
    }
   ],
   "source": [
    "from models.openvla_oft.configuration_prismatic import OpenVLAConfig\n",
    "from models.openvla_oft.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "print(\"*********USE VLA tokenizer*************\")\n",
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "processor = AutoProcessor.from_pretrained(local_path, trust_remote_code=True)\n",
    "tokenizer=processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b616f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">09/29 [06:57:58] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///root/.cache/huggingface/modules/transformers_modules/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/.cache/huggingface/modules/transformers_modules/modeling_prismatic.py#332\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">332</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.55</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m09/29 [06:57:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=896568;file:///root/.cache/huggingface/modules/transformers_modules/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=452700;file:///root/.cache/huggingface/modules/transformers_modules/modeling_prismatic.py#332\u001b\\\u001b[2m332\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.55\u001b[0m.\u001b[1;36m4\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m4\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVLAForActionPrediction(\n",
      "  (vision_backbone): PrismaticVisionBackbone(\n",
      "    (featurizer): VisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        (norm): Identity()\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (patch_drop): Identity()\n",
      "      (norm_pre): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (12): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (13): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (14): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (15): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (16): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (17): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (18): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (19): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (20): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (21): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (22): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (23): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (fc_norm): Identity()\n",
      "      (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      (head): Identity()\n",
      "    )\n",
      "    (fused_featurizer): VisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
      "        (norm): Identity()\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (patch_drop): Identity()\n",
      "      (norm_pre): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (12): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (13): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (14): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (15): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (16): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (17): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (18): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (19): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (20): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (21): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (22): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (23): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (24): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (25): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (26): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn_pool): AttentionPoolLatent(\n",
      "        (q): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (kv): Linear(in_features=1152, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (fc_norm): Identity()\n",
      "      (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      (head): Identity()\n",
      "    )\n",
      "  )\n",
      "  (projector): PrismaticProjector(\n",
      "    (fc1): Linear(in_features=2176, out_features=8704, bias=True)\n",
      "    (fc2): Linear(in_features=8704, out_features=4096, bias=True)\n",
      "    (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (act_fn1): GELU(approximate='none')\n",
      "    (act_fn2): GELU(approximate='none')\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaAttention(\n",
      "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "# override model kwargs\n",
    "actor_model_config = AutoConfig.from_pretrained(local_path, trust_remote_code=True)\n",
    "\n",
    "actor_module = AutoModelForVision2Seq.from_pretrained(\n",
    "                                        pretrained_model_name_or_path=local_path,\n",
    "                                        torch_dtype=torch_dtype,\n",
    "                                        #attn_implementation=\"flash_attention_2\",\n",
    "                                        config=actor_model_config,              \n",
    "                                        trust_remote_code=True,\n",
    "                                    )\n",
    "print(actor_module)\n",
    "#oft add\n",
    "actor_module.vision_backbone.set_num_images_in_input(1)\n",
    "\n",
    "dataset_statistics_path = os.path.join(local_path, \"dataset_statistics.json\")\n",
    "if os.path.isfile(dataset_statistics_path):\n",
    "    with open(dataset_statistics_path, \"r\") as f:\n",
    "        norm_stats = json.load(f)\n",
    "    actor_module.norm_stats = norm_stats\n",
    "else:\n",
    "    print(\n",
    "        \"WARNING: No local dataset_statistics.json file found for current checkpoint.\\n\"\n",
    "        \"You can ignore this if you are loading the base VLA (i.e. not fine-tuned) checkpoint.\"\n",
    "        \"Otherwise, you may run into errors when trying to call `predict_action()` due to an absent `unnorm_key`.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c571a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from env.libero_env import LiberoEnv\n",
    "from env.libero_utils import get_libero_image, quat2axisangle\n",
    "def _obs_to_input(obs):\n",
    "    # remove the wrist image\n",
    "    return {\n",
    "        \"full_image\": get_libero_image(obs, 224),\n",
    "        \"state\": np.concatenate([\n",
    "            obs[\"robot0_eef_pos\"],\n",
    "            quat2axisangle(obs[\"robot0_eef_quat\"]),\n",
    "            obs[\"robot0_gripper_qpos\"]\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168eaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def center_crop_image(image: Image.Image) -> Image.Image:\n",
    "\n",
    "    crop_scale = 0.9\n",
    "    orig_w, orig_h = image.size\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    crop_h = int(orig_h * crop_scale)\n",
    "    crop_w = int(orig_w * crop_scale)\n",
    "    image_tensor = F.center_crop(image_tensor, (crop_h, crop_w))\n",
    "    image_tensor = F.resize(image_tensor, (orig_h, orig_w))\n",
    "    final_image = F.to_pil_image(image_tensor)\n",
    "    \n",
    "    final_image = final_image.convert(\"RGB\")\n",
    "    return final_image\n",
    "\n",
    "def process_input(inputs:list, task_descriptions:list, config):\n",
    "    \n",
    "    batchdata = {\"input_ids\":[],\"attention_mask\":[],\"pixel_values\":[]}  \n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i]\n",
    "        task_description = task_descriptions[i]\n",
    "        \n",
    "        image = Image.fromarray(input[\"full_image\"]).convert(\"RGB\")\n",
    "        if config[\"center_crop\"]:\n",
    "            image = center_crop_image(image)\n",
    "        prompt = f\"In: What action should the robot take to {task_description.lower()}?\\nOut:\"\n",
    "        batch_feature  = processor(prompt, image)\n",
    "        \n",
    "        if \"wrist_image\" in input.keys():\n",
    "            wrist_image = Image.fromarray(input[\"wrist_image\"]).convert(\"RGB\")\n",
    "            if config[\"center_crop\"]:\n",
    "                wrist_image = center_crop_image(wrist_image)\n",
    "            wrist_batch_feature = processor(prompt, wrist_image)\n",
    "            primary_pixel_values = batch_feature[\"pixel_values\"]\n",
    "            batch_feature[\"pixel_values\"] = torch.cat([primary_pixel_values] + [wrist_batch_feature[\"pixel_values\"]], dim=1)\n",
    "            \n",
    "        input_ids = batch_feature[\"input_ids\"]\n",
    "        attention_mask = batch_feature[\"attention_mask\"]\n",
    "        pixel_values = batch_feature[\"pixel_values\"]\n",
    "        \n",
    "        if not torch.all(input_ids[:, -1] == 29871):\n",
    "            input_ids = torch.cat(\n",
    "                (input_ids, torch.unsqueeze(torch.Tensor([29871]).long(), dim=0).to(input_ids.device)), dim=1\n",
    "            )\n",
    "            attention_mask = torch.cat(\n",
    "                (attention_mask, torch.unsqueeze(torch.Tensor([True]).bool(), dim=0).to(attention_mask.device)), dim=1\n",
    "            )\n",
    "        \n",
    "        batchdata[\"input_ids\"].append(input_ids)    \n",
    "        batchdata[\"attention_mask\"].append(attention_mask)    \n",
    "        batchdata[\"pixel_values\"].append(pixel_values)    \n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda') \n",
    "    \n",
    "    batchdata[\"input_ids\"] = [x.transpose(0, 1) for x in batchdata[\"input_ids\"]]\n",
    "    batchdata[\"attention_mask\"] = [x.transpose(0, 1) for x in batchdata[\"attention_mask\"]]\n",
    "    batchdata[\"input_ids\"] = pad_sequence(batchdata[\"input_ids\"], batch_first=True, padding_value=processor.tokenizer.pad_token_id).squeeze(-1).to(device)\n",
    "    batchdata[\"attention_mask\"] = pad_sequence(batchdata[\"attention_mask\"], batch_first=True, padding_value=0).squeeze(-1).to(device)\n",
    "    \n",
    "    padding_mask = batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id)\n",
    "    assert  torch.all(padding_mask==batchdata[\"attention_mask\"].ne(0))\n",
    "    padding_mask = ~padding_mask\n",
    "    padding_mask = padding_mask.int() \n",
    "    sorted_indices = torch.argsort(padding_mask, dim=1, descending=True, stable=True)\n",
    "    batchdata[\"input_ids\"] = torch.gather(batchdata[\"input_ids\"], 1, sorted_indices)\n",
    "    batchdata[\"attention_mask\"] = torch.gather(batchdata[\"attention_mask\"], 1, sorted_indices)\n",
    "    \n",
    "    \n",
    "    batchdata[\"pixel_values\"] = torch.cat(batchdata[\"pixel_values\"] , dim=0).to(device)\n",
    "    assert torch.all(batchdata[\"attention_mask\"].ne(0) == batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id))\n",
    "\n",
    "    return batchdata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346164af",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_module = actor_module.to('cuda')\n",
    "actor_module.eval()\n",
    "actor_module.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO_SAMPLE = True\n",
    "DO_SAMPLE = False\n",
    "TEMP = 1.6\n",
    "# TEMP = 0.2\n",
    "UNNORM_KEY = \"libero_10\"\n",
    "UNNORM_KEY = f\"{UNNORM_KEY}_no_noops\"\n",
    "MAX_PROMPT_LENGTH = 512\n",
    "def pad_sequence_to_length(tensors, max_seq_len, pad_token_id, left_pad=False):\n",
    "    \"\"\"\n",
    "    pad a 2D tensors (e.g. responses, logprobs) in the last dim to max_seq_length.\n",
    "    input shape: [bs, seq_length]\n",
    "    output shape: [bs, max_seq_length]\n",
    "    (0, max_seq_len - tensors.shape[-1]) means right pad to max_seq_length and no left pad\n",
    "    \"\"\"\n",
    "    if tensors.shape[-1] >= max_seq_len:\n",
    "        return tensors\n",
    "    pad_tuple = (max_seq_len - tensors.shape[-1], 0) if left_pad else (0, max_seq_len - tensors.shape[-1])\n",
    "    return torch.nn.functional.pad(tensors, pad_tuple, 'constant', pad_token_id)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _generate_one_step(prompts: dict):\n",
    "    idx = prompts['input_ids']  # (bs, prompt_length)\n",
    "    attention_mask = prompts['attention_mask']  # left-padded attention_mask\n",
    "    pixel_values = prompts[\"pixel_values\"]\n",
    "\n",
    "\n",
    "\n",
    "    # make sampling args can be overriden by inputs\n",
    "    do_sample = prompts.get('do_sample', DO_SAMPLE)\n",
    "\n",
    "\n",
    "    temperature = prompts.get('temperature', TEMP)\n",
    "\n",
    "    #generation_config = GenerationConfig(temperature=temperature, top_p=top_p, top_k=top_k)\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        actions, response = actor_module.generate_action_verl(\n",
    "            input_ids=idx,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            padding_idx = processor.tokenizer.pad_token_id,\n",
    "            do_sample=do_sample,\n",
    "            unnorm_key= UNNORM_KEY,\n",
    "            temperature=temperature, )\n",
    "    \n",
    "    \n",
    "    assert processor.tokenizer.pad_token_id is not None\n",
    "\n",
    "    assert idx.ndim == 2\n",
    "    idx = pad_sequence_to_length(idx,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=processor.tokenizer.pad_token_id,left_pad=True)\n",
    "    \n",
    "    assert attention_mask.ndim == 2\n",
    "    attention_mask = pad_sequence_to_length(attention_mask,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=0,left_pad=True)\n",
    "    \n",
    "    \n",
    "    assert idx.device.type == 'cuda'\n",
    "    assert response.device.type == 'cuda'\n",
    "    #assert seq.device.type == 'cuda'\n",
    "    assert attention_mask.device.type == 'cuda'\n",
    "    assert pixel_values.device.type == 'cuda'\n",
    "    batch ={\n",
    "            'responses': response,\n",
    "            'input_ids': idx,\n",
    "            'attention_mask': attention_mask,\n",
    "            \"pixel_values\":pixel_values,\n",
    "            \"action\":actions,\n",
    "        }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd03b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "Initial data: {'type': 'init', 'obs': OrderedDict([('robot0_joint_pos', array([ 0.01827163, -0.16448719,  0.02169336, -2.40270198,  0.00596934,\n",
      "        2.18337463,  0.81767892])), ('robot0_joint_pos_cos', array([ 0.99983308,  0.98650246,  0.99976471, -0.73921611,  0.99998218,\n",
      "       -0.57497885,  0.68391642])), ('robot0_joint_pos_sin', array([ 0.01827062, -0.16374646,  0.02169166, -0.67346829,  0.0059693 ,\n",
      "        0.81816827,  0.72956037])), ('robot0_joint_vel', array([-0.01455697,  0.02580653,  0.01168757,  0.0449542 ,  0.00851403,\n",
      "       -0.0541633 ,  0.01900455])), ('robot0_eef_pos', array([-0.20136824,  0.01869972,  1.18931828])), ('robot0_eef_quat', array([ 9.99622153e-01,  2.13634188e-03, -2.74017070e-02,  3.65594565e-04])), ('robot0_gripper_qpos', array([ 0.03872169, -0.03872389])), ('robot0_gripper_qvel', array([ 0.00326249, -0.00326401])), ('agentview_image', array([[[201, 183, 163],\n",
      "        [200, 182, 162],\n",
      "        [200, 182, 162],\n",
      "        ...,\n",
      "        [197, 180, 164],\n",
      "        [194, 177, 161],\n",
      "        [199, 182, 166]],\n",
      "\n",
      "       [[202, 185, 165],\n",
      "        [200, 183, 163],\n",
      "        [200, 182, 162],\n",
      "        ...,\n",
      "        [196, 179, 163],\n",
      "        [195, 178, 162],\n",
      "        [202, 185, 169]],\n",
      "\n",
      "       [[200, 183, 163],\n",
      "        [199, 182, 162],\n",
      "        [199, 181, 161],\n",
      "        ...,\n",
      "        [195, 178, 162],\n",
      "        [196, 179, 163],\n",
      "        [201, 184, 168]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 16,  16,  16],\n",
      "        [ 15,  15,  15],\n",
      "        [ 15,  15,  15],\n",
      "        ...,\n",
      "        [ 10,  10,   8],\n",
      "        [ 10,  10,   8],\n",
      "        [ 10,  10,   8]],\n",
      "\n",
      "       [[ 22,  22,  22],\n",
      "        [ 20,  20,  20],\n",
      "        [ 18,  18,  18],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[114, 114, 114],\n",
      "        [106, 106, 106],\n",
      "        [ 93,  93,  93],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)), ('robot0_eye_in_hand_image', array([[[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       [[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       [[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[196, 179, 163],\n",
      "        [199, 182, 166],\n",
      "        [199, 182, 165],\n",
      "        ...,\n",
      "        [196, 179, 161],\n",
      "        [193, 176, 159],\n",
      "        [191, 173, 156]],\n",
      "\n",
      "       [[196, 179, 163],\n",
      "        [197, 180, 164],\n",
      "        [198, 181, 164],\n",
      "        ...,\n",
      "        [197, 180, 162],\n",
      "        [194, 177, 159],\n",
      "        [192, 174, 158]],\n",
      "\n",
      "       [[196, 179, 163],\n",
      "        [196, 179, 163],\n",
      "        [197, 180, 164],\n",
      "        ...,\n",
      "        [197, 180, 162],\n",
      "        [194, 177, 160],\n",
      "        [193, 175, 159]]], dtype=uint8)), ('chefmate_8_frypan_1_pos', array([-0.07424537, -0.27227411,  0.89917071])), ('chefmate_8_frypan_1_quat', array([-7.82723022e-05,  8.42990838e-05,  7.07107006e-01,  7.07106547e-01])), ('chefmate_8_frypan_1_to_robot0_eef_pos', array([0.14158939, 0.29133852, 0.28299465])), ('chefmate_8_frypan_1_to_robot0_eef_quat', array([ 0.70835227, -0.705327  , -0.01955   ,  0.01919548], dtype=float32)), ('moka_pot_1_pos', array([ 0.03027254, -0.00733274,  0.96610585])), ('moka_pot_1_quat', array([ 2.06958022e-07, -4.60960356e-06,  1.00000000e+00, -3.30389875e-10])), ('moka_pot_1_to_robot0_eef_pos', array([0.24340867, 0.0268892 , 0.21020978])), ('moka_pot_1_to_robot0_eef_quat', array([ 2.1362144e-03, -9.9962229e-01, -3.7020462e-04,  2.7401509e-02],\n",
      "      dtype=float32)), ('robot0_proprio-state', array([ 1.82716348e-02, -1.64487187e-01,  2.16933629e-02, -2.40270198e+00,\n",
      "        5.96933631e-03,  2.18337463e+00,  8.17678918e-01,  9.99833078e-01,\n",
      "        9.86502456e-01,  9.99764708e-01, -7.39216111e-01,  9.99982184e-01,\n",
      "       -5.74978853e-01,  6.83916417e-01,  1.82706181e-02, -1.63746462e-01,\n",
      "        2.16916615e-02, -6.73468293e-01,  5.96930086e-03,  8.18168270e-01,\n",
      "        7.29560370e-01, -1.45569721e-02,  2.58065319e-02,  1.16875662e-02,\n",
      "        4.49541970e-02,  8.51402777e-03, -5.41633034e-02,  1.90045542e-02,\n",
      "       -2.01368242e-01,  1.86997222e-02,  1.18931828e+00,  9.99622153e-01,\n",
      "        2.13634188e-03, -2.74017070e-02,  3.65594565e-04,  3.87216861e-02,\n",
      "       -3.87238927e-02,  3.26248532e-03, -3.26400839e-03])), ('object-state', array([-7.42453734e-02, -2.72274107e-01,  8.99170708e-01, -7.82723022e-05,\n",
      "        8.42990838e-05,  7.07107006e-01,  7.07106547e-01,  1.41589391e-01,\n",
      "        2.91338519e-01,  2.82994649e-01,  7.08352268e-01, -7.05326974e-01,\n",
      "       -1.95499994e-02,  1.91954840e-02,  3.02725352e-02, -7.33273512e-03,\n",
      "        9.66105847e-01,  2.06958022e-07, -4.60960356e-06,  1.00000000e+00,\n",
      "       -3.30389875e-10,  2.43408669e-01,  2.68891950e-02,  2.10209776e-01,\n",
      "        2.13621440e-03, -9.99622285e-01, -3.70204623e-04,  2.74015088e-02]))]), 'task_description': 'turn on the stove and put the moka pot on it', 'valid_images': [array([[[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [ 93,  93,  93],\n",
      "        [106, 106, 106],\n",
      "        [114, 114, 114]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [ 18,  18,  18],\n",
      "        [ 20,  20,  20],\n",
      "        [ 22,  22,  22]],\n",
      "\n",
      "       [[ 10,  10,   8],\n",
      "        [ 10,  10,   8],\n",
      "        [ 10,  10,   8],\n",
      "        ...,\n",
      "        [ 15,  15,  15],\n",
      "        [ 15,  15,  15],\n",
      "        [ 16,  16,  16]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[201, 184, 168],\n",
      "        [196, 179, 163],\n",
      "        [195, 178, 162],\n",
      "        ...,\n",
      "        [199, 181, 161],\n",
      "        [199, 182, 162],\n",
      "        [200, 183, 163]],\n",
      "\n",
      "       [[202, 185, 169],\n",
      "        [195, 178, 162],\n",
      "        [196, 179, 163],\n",
      "        ...,\n",
      "        [200, 182, 162],\n",
      "        [200, 183, 163],\n",
      "        [202, 185, 165]],\n",
      "\n",
      "       [[199, 182, 166],\n",
      "        [194, 177, 161],\n",
      "        [197, 180, 164],\n",
      "        ...,\n",
      "        [200, 182, 162],\n",
      "        [200, 182, 162],\n",
      "        [201, 183, 163]]], dtype=uint8)], 'task_file_name': 'libero_10_task_2_trial_0', 'active': True, 'complete': False, 'finish_step': 0}\n",
      "Task description: ['turn on the stove and put the moka pot on it']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:31<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# from collections import defaultdict\n",
    "# import copy\n",
    "# import torch.cuda.profiler as profiler\n",
    "# from tqdm import trange\n",
    "\n",
    "# config = {\n",
    "#     \"center_crop\": True,\n",
    "#     \"num_steps_wait\": 10\n",
    "# }\n",
    "\n",
    "# batch_size = 32\n",
    "# # max_steps = 200\n",
    "# max_steps = 512\n",
    "# # max_steps = 1024\n",
    "# # max_steps = 256\n",
    "# action_chunks_len = 8\n",
    "# # with torch.profiler.profile(\n",
    "# #             activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "# #             profile_memory=True,  # 内存数据采集的开关\n",
    "# #             record_shapes=True,  # 算子input shape信息采集的开关\n",
    "# #             with_stack=True,\n",
    "# #             with_flops=True,\n",
    "# #             with_modules=True,\n",
    "# #             schedule=torch.profiler.schedule(wait=10, warmup=1, active=3, repeat=2),\n",
    "# #             on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./traces\")\n",
    "# #     ) as prof:\n",
    "# if True:\n",
    "#     # libero_env = LiberoEnv(task_name=\"libero_goal\", task_id=1, trial_id=0, is_valid=True, max_steps=50, config=config)\n",
    "#     libero_env = LiberoEnv(task_name=\"libero_10\", task_id=2, trial_id=0, is_valid=True, max_steps=max_steps, config=config)\n",
    "#     valid_video = defaultdict(list)\n",
    "#     vla_history = []\n",
    "#     init_data = libero_env.get_initial_state()\n",
    "#     print(\"Initial data:\", init_data)\n",
    "#     task_descriptions = [init_data['task_description']]\n",
    "#     print(f\"Task description: {task_descriptions}\")\n",
    "\n",
    "#     valid_video[init_data['task_file_name']].extend(init_data['valid_images'])\n",
    "#     env_data = copy.deepcopy(init_data)\n",
    "#     env_obs = env_data['obs']\n",
    "#     for step in trange(max_steps // action_chunks_len):\n",
    "#         # print(\"Step:\", step)\n",
    "#         # prof.step()\n",
    "#         inputs = [_obs_to_input(env_obs)]\n",
    "#         vla_input = process_input(inputs, task_descriptions, config)\n",
    "#         # vla_input.update(meta_info)\n",
    "#         vla_output = _generate_one_step(vla_input)\n",
    "#         actions = vla_output[\"action\"]\n",
    "#         step_data = {\n",
    "#             \"responses\": vla_output[\"responses\"],\n",
    "#             \"input_ids\": vla_output[\"input_ids\"],\n",
    "#             \"attention_mask\": vla_output[\"attention_mask\"],\n",
    "#             \"pixel_values\": vla_output[\"pixel_values\"],\n",
    "#             \"action\": actions,\n",
    "#             \"step\": step\n",
    "#         }\n",
    "#         vla_history.append(step_data)\n",
    "        \n",
    "\n",
    "#         result = libero_env.step(actions[0])\n",
    "#         valid_video[init_data['task_file_name']].extend(result['valid_images'])\n",
    "#         env_obs = result[\"obs\"]\n",
    "\n",
    "#         step += action_chunks_len\n",
    "#         complete = result[\"complete\"]\n",
    "#         if complete:\n",
    "#             print(f\"Task completed at step {step}.\")\n",
    "#             break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe397993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist![info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "All environments initialized successfully.\n",
      "Initial data (env 0): {'type': 'init', 'obs': OrderedDict([('robot0_joint_pos', array([-1.17963417e-02, -1.57304113e-01,  4.07893630e-03, -2.38174999e+00,\n",
      "        5.86564150e-04,  2.17044289e+00,  7.78661591e-01])), ('robot0_joint_pos_cos', array([ 0.99993042,  0.9876532 ,  0.99999168, -0.72494439,  0.99999983,\n",
      "       -0.56435074,  0.71185418])), ('robot0_joint_pos_sin', array([-1.17960681e-02, -1.56656177e-01,  4.07892499e-03, -6.88807396e-01,\n",
      "        5.86564117e-04,  8.25535128e-01,  7.02327296e-01])), ('robot0_joint_vel', array([ 0.0148748 ,  0.0411153 , -0.01270228,  0.07212618, -0.00353942,\n",
      "       -0.08609378, -0.0004995 ])), ('robot0_eef_pos', array([-0.04614927, -0.00356789,  0.7020463 ])), ('robot0_eef_quat', array([ 9.99636845e-01, -4.54802051e-04, -2.69435911e-02, -1.20957609e-04])), ('robot0_gripper_qpos', array([ 0.03872318, -0.0387224 ])), ('robot0_gripper_qvel', array([ 0.00326321, -0.00326311])), ('agentview_image', array([[[ 82,  58,  45],\n",
      "        [ 80,  58,  44],\n",
      "        [ 79,  57,  45],\n",
      "        ...,\n",
      "        [ 75,  55,  48],\n",
      "        [ 74,  54,  47],\n",
      "        [ 76,  56,  47]],\n",
      "\n",
      "       [[ 83,  58,  46],\n",
      "        [ 82,  56,  45],\n",
      "        [ 82,  57,  45],\n",
      "        ...,\n",
      "        [ 74,  56,  46],\n",
      "        [ 74,  54,  44],\n",
      "        [ 80,  58,  46]],\n",
      "\n",
      "       [[ 72,  52,  41],\n",
      "        [ 73,  52,  42],\n",
      "        [ 74,  53,  42],\n",
      "        ...,\n",
      "        [ 86,  60,  47],\n",
      "        [ 88,  61,  48],\n",
      "        [ 90,  62,  50]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[115, 113, 110],\n",
      "        [116, 114, 110],\n",
      "        [116, 114, 111],\n",
      "        ...,\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13]],\n",
      "\n",
      "       [[114, 112, 109],\n",
      "        [116, 114, 110],\n",
      "        [116, 114, 111],\n",
      "        ...,\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13]],\n",
      "\n",
      "       [[115, 112, 108],\n",
      "        [115, 114, 110],\n",
      "        [116, 114, 111],\n",
      "        ...,\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13]]], dtype=uint8)), ('robot0_eye_in_hand_image', array([[[ 56,  56,  56],\n",
      "        [ 56,  56,  56],\n",
      "        [ 56,  56,  56],\n",
      "        ...,\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55]],\n",
      "\n",
      "       [[ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        ...,\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55]],\n",
      "\n",
      "       [[ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        [ 55,  55,  55],\n",
      "        ...,\n",
      "        [ 54,  54,  54],\n",
      "        [ 54,  54,  54],\n",
      "        [ 54,  54,  54]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 93,  67,  54],\n",
      "        [ 93,  66,  54],\n",
      "        [ 92,  65,  54],\n",
      "        ...,\n",
      "        [ 96,  69,  54],\n",
      "        [ 96,  71,  54],\n",
      "        [ 95,  69,  56]],\n",
      "\n",
      "       [[ 90,  65,  53],\n",
      "        [ 91,  66,  54],\n",
      "        [ 89,  66,  55],\n",
      "        ...,\n",
      "        [ 98,  71,  55],\n",
      "        [ 99,  72,  54],\n",
      "        [ 98,  71,  55]],\n",
      "\n",
      "       [[ 92,  66,  53],\n",
      "        [ 93,  68,  54],\n",
      "        [ 92,  69,  55],\n",
      "        ...,\n",
      "        [100,  72,  56],\n",
      "        [102,  74,  55],\n",
      "        [102,  73,  54]]], dtype=uint8)), ('alphabet_soup_1_pos', array([-0.10016029, -0.15201577,  0.47517012])), ('alphabet_soup_1_quat', array([ 0.00234641,  0.70745547,  0.70675012, -0.00235004])), ('alphabet_soup_1_to_robot0_eef_pos', array([-0.04157726,  0.14854659,  0.22941664])), ('alphabet_soup_1_to_robot0_eef_quat', array([ 0.01639105, -0.7064702 ,  0.7073484 ,  0.0170183 ], dtype=float32)), ('cream_cheese_1_pos', array([ 0.07851476, -0.19384593,  0.44569584])), ('cream_cheese_1_quat', array([-2.08023500e-15, -2.61916878e-16,  1.00000000e+00, -3.53890845e-24])), ('cream_cheese_1_to_robot0_eef_pos', array([0.13846376, 0.1902195 , 0.24921221])), ('cream_cheese_1_to_robot0_eef_quat', array([-4.5480178e-04, -9.9963701e-01,  1.2095745e-04,  2.6943589e-02],\n",
      "      dtype=float32)), ('tomato_sauce_1_pos', array([-0.11728698,  0.05574799,  0.47516915])), ('tomato_sauce_1_quat', array([ 0.00233695,  0.70745304,  0.70675263, -0.00233782])), ('tomato_sauce_1_to_robot0_eef_pos', array([-0.05886659, -0.0592014 ,  0.23039553])), ('tomato_sauce_1_to_robot0_eef_quat', array([ 0.0164032 , -0.70647216,  0.70734566,  0.01702782], dtype=float32)), ('ketchup_1_pos', array([-0.26846343, -0.14860774,  0.50917979])), ('ketchup_1_quat', array([0.50000001, 0.49999998, 0.49999999, 0.50000001])), ('ketchup_1_to_robot0_eef_pos', array([-0.21147107,  0.1452853 ,  0.20452336])), ('ketchup_1_to_robot0_eef_quat', array([-0.51312333,  0.5134571 , -0.48663443,  0.4860587 ], dtype=float32)), ('orange_juice_1_pos', array([ 0.00996837, -0.25922631,  0.50650984])), ('orange_juice_1_quat', array([0.5, 0.5, 0.5, 0.5])), ('orange_juice_1_to_robot0_eef_pos', array([0.06680004, 0.25564943, 0.19216153])), ('orange_juice_1_to_robot0_eef_quat', array([-0.5131232 ,  0.5134572 , -0.48663446,  0.4860587 ], dtype=float32)), ('milk_1_pos', array([ 0.04927007, -0.12142245,  0.50650984])), ('milk_1_quat', array([0.5, 0.5, 0.5, 0.5])), ('milk_1_to_robot0_eef_pos', array([0.10592026, 0.11780962, 0.19008114])), ('milk_1_to_robot0_eef_quat', array([-0.5131232 ,  0.5134572 , -0.48663446,  0.4860587 ], dtype=float32)), ('butter_1_pos', array([0.0704472 , 0.05265618, 0.44546986])), ('butter_1_quat', array([3.26158128e-14, 1.36999897e-15, 1.00000000e+00, 3.38295785e-23])), ('butter_1_to_robot0_eef_pos', array([ 0.13019757, -0.05627506,  0.24993811])), ('butter_1_to_robot0_eef_quat', array([-4.5480178e-04, -9.9963701e-01,  1.2095745e-04,  2.6943589e-02],\n",
      "      dtype=float32)), ('basket_1_pos', array([-0.00211551,  0.26899788,  0.43219203])), ('basket_1_quat', array([-0.00169499,  0.00169499,  0.70710475,  0.70710475])), ('basket_1_to_robot0_eef_pos', array([ 0.05826019, -0.27254734,  0.26716305])), ('basket_1_to_robot0_eef_quat', array([ 0.7065718 , -0.7071235 , -0.0172728 ,  0.02083261], dtype=float32)), ('robot0_proprio-state', array([-1.17963417e-02, -1.57304113e-01,  4.07893630e-03, -2.38174999e+00,\n",
      "        5.86564150e-04,  2.17044289e+00,  7.78661591e-01,  9.99930424e-01,\n",
      "        9.87653199e-01,  9.99991681e-01, -7.24944392e-01,  9.99999828e-01,\n",
      "       -5.64350736e-01,  7.11854177e-01, -1.17960681e-02, -1.56656177e-01,\n",
      "        4.07892499e-03, -6.88807396e-01,  5.86564117e-04,  8.25535128e-01,\n",
      "        7.02327296e-01,  1.48748029e-02,  4.11152965e-02, -1.27022791e-02,\n",
      "        7.21261830e-02, -3.53941788e-03, -8.60937754e-02, -4.99495992e-04,\n",
      "       -4.61492722e-02, -3.56789105e-03,  7.02046295e-01,  9.99636845e-01,\n",
      "       -4.54802051e-04, -2.69435911e-02, -1.20957609e-04,  3.87231829e-02,\n",
      "       -3.87223985e-02,  3.26321010e-03, -3.26310874e-03])), ('object-state', array([-1.00160288e-01, -1.52015770e-01,  4.75170124e-01,  2.34641389e-03,\n",
      "        7.07455471e-01,  7.06750118e-01, -2.35004040e-03, -4.15772575e-02,\n",
      "        1.48546590e-01,  2.29416638e-01,  1.63910538e-02, -7.06470191e-01,\n",
      "        7.07348406e-01,  1.70182995e-02,  7.85147562e-02, -1.93845933e-01,\n",
      "        4.45695844e-01, -2.08023500e-15, -2.61916878e-16,  1.00000000e+00,\n",
      "       -3.53890845e-24,  1.38463764e-01,  1.90219501e-01,  2.49212212e-01,\n",
      "       -4.54801775e-04, -9.99637008e-01,  1.20957448e-04,  2.69435886e-02,\n",
      "       -1.17286983e-01,  5.57479913e-02,  4.75169150e-01,  2.33694665e-03,\n",
      "        7.07453036e-01,  7.06752627e-01, -2.33781869e-03, -5.88665852e-02,\n",
      "       -5.92014037e-02,  2.30395527e-01,  1.64032038e-02, -7.06472158e-01,\n",
      "        7.07345665e-01,  1.70278214e-02, -2.68463432e-01, -1.48607743e-01,\n",
      "        5.09179795e-01,  5.00000011e-01,  4.99999983e-01,  4.99999994e-01,\n",
      "        5.00000012e-01, -2.11471072e-01,  1.45285301e-01,  2.04523359e-01,\n",
      "       -5.13123333e-01,  5.13457119e-01, -4.86634433e-01,  4.86058712e-01,\n",
      "        9.96836947e-03, -2.59226312e-01,  5.06509842e-01,  4.99999999e-01,\n",
      "        5.00000001e-01,  4.99999999e-01,  5.00000001e-01,  6.68000411e-02,\n",
      "        2.55649426e-01,  1.92161525e-01, -5.13123214e-01,  5.13457179e-01,\n",
      "       -4.86634463e-01,  4.86058712e-01,  4.92700672e-02, -1.21422445e-01,\n",
      "        5.06509842e-01,  5.00000001e-01,  4.99999999e-01,  5.00000001e-01,\n",
      "        4.99999999e-01,  1.05920257e-01,  1.17809617e-01,  1.90081143e-01,\n",
      "       -5.13123214e-01,  5.13457179e-01, -4.86634463e-01,  4.86058712e-01,\n",
      "        7.04471983e-02,  5.26561777e-02,  4.45469863e-01,  3.26158128e-14,\n",
      "        1.36999897e-15,  1.00000000e+00,  3.38295785e-23,  1.30197567e-01,\n",
      "       -5.62750640e-02,  2.49938107e-01, -4.54801775e-04, -9.99637008e-01,\n",
      "        1.20957448e-04,  2.69435886e-02, -2.11550503e-03,  2.68997879e-01,\n",
      "        4.32192027e-01, -1.69499089e-03,  1.69498882e-03,  7.07104750e-01,\n",
      "        7.07104749e-01,  5.82601908e-02, -2.72547336e-01,  2.67163048e-01,\n",
      "        7.06571817e-01, -7.07123518e-01, -1.72728039e-02,  2.08326131e-02]))]), 'task_description': 'put both the alphabet soup and the tomato sauce in the basket', 'valid_images': [array([[[ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [116, 114, 111],\n",
      "        [115, 114, 110],\n",
      "        [115, 112, 108]],\n",
      "\n",
      "       [[ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [116, 114, 111],\n",
      "        [116, 114, 110],\n",
      "        [114, 112, 109]],\n",
      "\n",
      "       [[ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [116, 114, 111],\n",
      "        [116, 114, 110],\n",
      "        [115, 113, 110]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 90,  62,  50],\n",
      "        [ 88,  61,  48],\n",
      "        [ 86,  60,  47],\n",
      "        ...,\n",
      "        [ 74,  53,  42],\n",
      "        [ 73,  52,  42],\n",
      "        [ 72,  52,  41]],\n",
      "\n",
      "       [[ 80,  58,  46],\n",
      "        [ 74,  54,  44],\n",
      "        [ 74,  56,  46],\n",
      "        ...,\n",
      "        [ 82,  57,  45],\n",
      "        [ 82,  56,  45],\n",
      "        [ 83,  58,  46]],\n",
      "\n",
      "       [[ 76,  56,  47],\n",
      "        [ 74,  54,  47],\n",
      "        [ 75,  55,  48],\n",
      "        ...,\n",
      "        [ 79,  57,  45],\n",
      "        [ 80,  58,  44],\n",
      "        [ 82,  58,  45]]], dtype=uint8)], 'task_file_name': 'libero_10_task_0_trial_0', 'active': True, 'complete': False, 'finish_step': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]/file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  return Image.fromarray(npimg, mode=mode)\n",
      " 50%|█████     | 32/64 [01:28<01:28,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 30 completed at step ~256!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 35/64 [01:37<01:22,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 31 completed at step ~280!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 36/64 [01:39<01:19,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 27 completed at step ~288!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 37/64 [01:42<01:15,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 20 completed at step ~296!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 39/64 [01:47<01:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 12 completed at step ~312!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 40/64 [01:50<01:04,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 10 completed at step ~320!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 43/64 [01:58<00:54,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 25 completed at step ~344!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 44/64 [02:00<00:51,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 28 completed at step ~352!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 45/64 [02:03<00:48,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 22 completed at step ~360!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 47/64 [02:07<00:41,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 6 completed at step ~376!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 49/64 [02:12<00:35,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 16 completed at step ~392!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 53/64 [02:21<00:24,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env 23 completed at step ~424!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:45<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing all environments...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from env.libero_env import SubprocVecEnv\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "from tqdm import trange\n",
    "config = {\n",
    "    \"center_crop\": True,\n",
    "    \"num_steps_wait\": 10\n",
    "}\n",
    "batch_size = 32\n",
    "max_steps = 512\n",
    "action_chunks_len = 8\n",
    "# ------------------------------\n",
    "# 1. 创建环境构造函数列表\n",
    "# ------------------------------\n",
    "# 使用 lambda 函数延迟环境的创建，直到子进程中才真正执行\n",
    "env_fns = [\n",
    "    lambda i=i: LiberoEnv(\n",
    "        task_name=\"libero_10\",\n",
    "        task_id=0,\n",
    "        trial_id=i,  # 每个环境 trial_id 不同\n",
    "        is_valid=True,\n",
    "        max_steps=max_steps,\n",
    "        config=config\n",
    "    )\n",
    "    for i in range(batch_size)\n",
    "]\n",
    "# ------------------------------\n",
    "# 2. 初始化向量化环境\n",
    "# ------------------------------\n",
    "vec_env = SubprocVecEnv(env_fns)\n",
    "\n",
    "# 获取所有环境的初始状态\n",
    "init_datas = vec_env.get_initial_states()\n",
    "print(f\"Initial data (env 0): {init_datas[0]}\")\n",
    "# 初始化任务描述、观测、视频存储和活跃状态\n",
    "task_descriptions = [data['task_description'] for data in init_datas]\n",
    "env_obs = [data['obs'] for data in init_datas]\n",
    "\n",
    "valid_video = defaultdict(list)\n",
    "for env_idx, data in enumerate(init_datas):\n",
    "    key = f\"{data['task_file_name']}_env{env_idx}\"\n",
    "    valid_video[key].extend(data['valid_images'])\n",
    "    \n",
    "dones = [False] * batch_size\n",
    "vla_history = [] \n",
    "# ------------------------------\n",
    "# 3. 主循环\n",
    "# ------------------------------\n",
    "total_chunks = max_steps // action_chunks_len\n",
    "for chunk_idx in trange(total_chunks):\n",
    "    active_envs_indices = [i for i, done in enumerate(dones) if not done]\n",
    "    \n",
    "    if not active_envs_indices:\n",
    "        print(\"All environments completed!\")\n",
    "        break\n",
    "    # 3.1 批量生成动作 (仅为活跃环境)\n",
    "    active_obs = [env_obs[i] for i in active_envs_indices]\n",
    "    active_task_desc = [task_descriptions[i] for i in active_envs_indices]\n",
    "    inputs = [_obs_to_input(obs) for obs in active_obs]\n",
    "    vla_input = process_input(inputs, active_task_desc, config)\n",
    "    vla_output = _generate_one_step(vla_input)\n",
    "    actions = vla_output[\"action\"]  # shape: (num_active, action_chunks_len, ...)\n",
    "    # 3.2 在子进程中并行执行动作\n",
    "    # actions 的数量必须和 active_envs_indices 的数量匹配\n",
    "    results = vec_env.step(actions, active_envs_indices)\n",
    "    # 3.3 更新状态、视频和完成标志\n",
    "    for i, env_idx in enumerate(active_envs_indices):\n",
    "        result = results[env_idx] # 从完整结果列表中获取对应环境的结果\n",
    "        \n",
    "        # 更新观测\n",
    "        env_obs[env_idx] = result[\"obs\"]\n",
    "        \n",
    "        # 更新视频\n",
    "        key = f\"{init_datas[env_idx]['task_file_name']}_env{env_idx}\"\n",
    "        valid_video[key].extend(result['valid_images'])\n",
    "        \n",
    "        # 更新完成状态\n",
    "        if result[\"complete\"]:\n",
    "            dones[env_idx] = True\n",
    "            total_step = (chunk_idx + 1) * action_chunks_len\n",
    "            print(f\"Env {env_idx} completed at step ~{total_step}!\")\n",
    "# ------------------------------\n",
    "# 4. 清理\n",
    "# ------------------------------\n",
    "print(\"Closing all environments...\")\n",
    "vec_env.close()\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656abcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['libero_10_task_0_trial_0_env0', 'libero_10_task_0_trial_1_env1', 'libero_10_task_0_trial_2_env2', 'libero_10_task_0_trial_3_env3', 'libero_10_task_0_trial_4_env4', 'libero_10_task_0_trial_5_env5', 'libero_10_task_0_trial_6_env6', 'libero_10_task_0_trial_7_env7', 'libero_10_task_0_trial_8_env8', 'libero_10_task_0_trial_9_env9', 'libero_10_task_0_trial_10_env10', 'libero_10_task_0_trial_11_env11', 'libero_10_task_0_trial_12_env12', 'libero_10_task_0_trial_13_env13', 'libero_10_task_0_trial_14_env14', 'libero_10_task_0_trial_15_env15', 'libero_10_task_0_trial_16_env16', 'libero_10_task_0_trial_17_env17', 'libero_10_task_0_trial_18_env18', 'libero_10_task_0_trial_19_env19', 'libero_10_task_0_trial_20_env20', 'libero_10_task_0_trial_21_env21', 'libero_10_task_0_trial_22_env22', 'libero_10_task_0_trial_23_env23', 'libero_10_task_0_trial_24_env24', 'libero_10_task_0_trial_25_env25', 'libero_10_task_0_trial_26_env26', 'libero_10_task_0_trial_27_env27', 'libero_10_task_0_trial_28_env28', 'libero_10_task_0_trial_29_env29', 'libero_10_task_0_trial_30_env30', 'libero_10_task_0_trial_31_env31', 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(valid_video)\n",
    "valid_video.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(valid_video['libero_10_task_0_trial_0_env0'])\n",
    "succeessful_videos = {key: valid_video[key] for key in valid_video if len(valid_video[key]) < 513}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b1bf284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(succeessful_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b3dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vla_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce27b667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['libero_goal_task_0_trial_0'])\n"
     ]
    }
   ],
   "source": [
    "print(valid_video.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e9072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import random\n",
    "def save_rollout_video(rollout_images, exp_name, task_name, step_idx, success ):\n",
    "    \"\"\"Saves an MP4 replay of an episode.\"\"\"\n",
    "    rollout_dir = f\"./rollouts/{exp_name}\" \n",
    "    os.makedirs(rollout_dir, exist_ok=True)\n",
    "    ran_id = random.randint(1, 10000)\n",
    "    #processed_task_description = task_description.lower().replace(\" \", \"_\").replace(\"\\n\", \"_\").replace(\".\", \"_\")[:50]\n",
    "    mp4_path = f\"{rollout_dir}/step={step_idx}--task={task_name}--success={success}--ran={ran_id}.mp4\"\n",
    "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "    for img in rollout_images:\n",
    "        video_writer.append_data(img)\n",
    "    video_writer.close()\n",
    "    print(f\"Saved rollout MP4 at path {mp4_path}\")\n",
    "    return mp4_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c04d77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_6_env6--success=True--ran=8333.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_10_env10--success=True--ran=3105.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_12_env12--success=True--ran=4885.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_16_env16--success=True--ran=7407.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_20_env20--success=True--ran=9007.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_22_env22--success=True--ran=9986.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_23_env23--success=True--ran=5638.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_25_env25--success=True--ran=6993.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_27_env27--success=True--ran=3912.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_28_env28--success=True--ran=9492.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_30_env30--success=True--ran=6234.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_10_task_0_trial_31_env31--success=True--ran=2258.mp4\n",
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=0--success=True--ran=526.mp4\n",
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=1--success=True--ran=4496.mp4\n"
     ]
    }
   ],
   "source": [
    "for task_file, images in succeessful_videos.items():\n",
    "    # complete = any(r['complete'] for r in task_records if r['task_file_name'] == task_file)\n",
    "    complete = True\n",
    "    save_rollout_video(\n",
    "        images,\n",
    "        \"0\",\n",
    "        task_file,\n",
    "        0,\n",
    "        complete\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-rollout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
