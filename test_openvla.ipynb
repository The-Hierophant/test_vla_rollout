{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943ac22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.openvla_oft.configuration_prismatic import OpenVLAConfig\n",
    "from models.openvla_oft.modeling_prismatic import OpenVLAForActionPrediction\n",
    "from models.openvla_oft.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "# from models.openvla_oft.openvla_utils import update_auto_map, check_model_logic_mismatch\n",
    "from transformers import AutoConfig, AutoImageProcessor, AutoModelForVision2Seq, AutoProcessor\n",
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoImageProcessor.register(OpenVLAConfig, PrismaticImageProcessor)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "AutoModelForVision2Seq.register(OpenVLAConfig, OpenVLAForActionPrediction)\n",
    "local_path = \"/file_system/common-models/SimpleVLA-RL/Openvla-oft-SFT-libero10-trajall\"\n",
    "# if self.rank == 0:\n",
    "#update_auto_map(local_path)\n",
    "#check_model_logic_mismatch(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd0ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********USE VLA tokenizer*************\n"
     ]
    }
   ],
   "source": [
    "from models.openvla_oft.configuration_prismatic import OpenVLAConfig\n",
    "from models.openvla_oft.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "print(\"*********USE VLA tokenizer*************\")\n",
    "AutoConfig.register(\"openvla\", OpenVLAConfig)\n",
    "AutoProcessor.register(OpenVLAConfig, PrismaticProcessor)\n",
    "processor = AutoProcessor.from_pretrained(local_path, trust_remote_code=True)\n",
    "tokenizer=processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">09/26 [03:25:13] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; Expected `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.40</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.19</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>`   <a href=\"file:///root/.cache/huggingface/modules/transformers_modules/Openvla-oft-SFT-libero10-trajall/modeling_prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/.cache/huggingface/modules/transformers_modules/Openvla-oft-SFT-libero10-trajall/modeling_prismatic.py#333\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">333</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         but got `<span style=\"color: #808000; text-decoration-color: #808000\">transformers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.55</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">tokenizers</span>==<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>`; there  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         might be inference-time regressions due to dependency changes.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         If in doubt, pleaseuse the above versions.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m09/26 [03:25:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> Expected `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.40\u001b[0m.\u001b[1;36m1\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m1\u001b[0m`   \u001b]8;id=699252;file:///root/.cache/huggingface/modules/transformers_modules/Openvla-oft-SFT-libero10-trajall/modeling_prismatic.py\u001b\\\u001b[2mmodeling_prismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=722547;file:///root/.cache/huggingface/modules/transformers_modules/Openvla-oft-SFT-libero10-trajall/modeling_prismatic.py#333\u001b\\\u001b[2m333\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         but got `\u001b[33mtransformers\u001b[0m==\u001b[1;36m4.55\u001b[0m.\u001b[1;36m4\u001b[0m` and `\u001b[33mtokenizers\u001b[0m==\u001b[1;36m0.21\u001b[0m.\u001b[1;36m4\u001b[0m`; there  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         might be inference-time regressions due to dependency changes.  \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         If in doubt, pleaseuse the above versions.                      \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVLAForActionPrediction(\n",
      "  (vision_backbone): PrismaticVisionBackbone(\n",
      "    (featurizer): VisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        (norm): Identity()\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (patch_drop): Identity()\n",
      "      (norm_pre): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (12): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (13): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (14): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (15): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (16): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (17): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (18): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (19): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (20): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (21): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (22): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (23): Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): LayerScale()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): LayerScale()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (fc_norm): Identity()\n",
      "      (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      (head): Identity()\n",
      "    )\n",
      "    (fused_featurizer): VisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
      "        (norm): Identity()\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (patch_drop): Identity()\n",
      "      (norm_pre): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (12): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (13): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (14): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (15): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (16): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (17): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (18): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (19): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (20): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (21): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (22): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (23): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (24): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (25): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (26): Block(\n",
      "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn_pool): AttentionPoolLatent(\n",
      "        (q): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (kv): Linear(in_features=1152, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (fc_norm): Identity()\n",
      "      (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      (head): Identity()\n",
      "    )\n",
      "  )\n",
      "  (projector): PrismaticProjector(\n",
      "    (fc1): Linear(in_features=2176, out_features=8704, bias=True)\n",
      "    (fc2): Linear(in_features=8704, out_features=4096, bias=True)\n",
      "    (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (act_fn1): GELU(approximate='none')\n",
      "    (act_fn2): GELU(approximate='none')\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaAttention(\n",
      "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "# override model kwargs\n",
    "actor_model_config = AutoConfig.from_pretrained(local_path, trust_remote_code=True)\n",
    "\n",
    "actor_module = AutoModelForVision2Seq.from_pretrained(\n",
    "                                        pretrained_model_name_or_path=local_path,\n",
    "                                        torch_dtype=torch_dtype,\n",
    "                                        #attn_implementation=\"flash_attention_2\",\n",
    "                                        config=actor_model_config,              \n",
    "                                        trust_remote_code=True,\n",
    "                                    )\n",
    "print(actor_module)\n",
    "#oft add\n",
    "actor_module.vision_backbone.set_num_images_in_input(1)\n",
    "\n",
    "dataset_statistics_path = os.path.join(local_path, \"dataset_statistics.json\")\n",
    "if os.path.isfile(dataset_statistics_path):\n",
    "    with open(dataset_statistics_path, \"r\") as f:\n",
    "        norm_stats = json.load(f)\n",
    "    actor_module.norm_stats = norm_stats\n",
    "else:\n",
    "    print(\n",
    "        \"WARNING: No local dataset_statistics.json file found for current checkpoint.\\n\"\n",
    "        \"You can ignore this if you are loading the base VLA (i.e. not fine-tuned) checkpoint.\"\n",
    "        \"Otherwise, you may run into errors when trying to call `predict_action()` due to an absent `unnorm_key`.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c571a10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (__init__.py:7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">09/26 [03:25:45] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; No private macro file found!                                           <a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m09/26 [03:25:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> No private macro file found!                                           \u001b]8;id=896560;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=523408;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (__init__.py:8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; It is recommended to use a private macro file                          <a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#8\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> It is recommended to use a private macro file                          \u001b]8;id=315301;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=376803;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#8\u001b\\\u001b[2m8\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (__init__.py:9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> | &gt;&gt; To setup, run: python                                                  <a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#9\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/ro</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">bosuite/scripts/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">setup_macros.py</span>                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m | >> To setup, run: python                                                  \u001b]8;id=342092;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=688921;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/robosuite/__init__.py#9\u001b\\\u001b[2m9\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35m/file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/ro\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35mbosuite/scripts/\u001b[0m\u001b[95msetup_macros.py\u001b[0m                                             \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; No OpenGL_accelerate module loaded: No module named          <a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/OpenGL/acceleratesupport.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">acceleratesupport.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/OpenGL/acceleratesupport.py#24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'OpenGL_accelerate'</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> No OpenGL_accelerate module loaded: No module named          \u001b]8;id=585090;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/OpenGL/acceleratesupport.py\u001b\\\u001b[2macceleratesupport.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439828;file:///file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/OpenGL/acceleratesupport.py#24\u001b\\\u001b[2m24\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[32m'OpenGL_accelerate'\u001b[0m                                               \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from env.libero_env import LiberoEnv\n",
    "from env.libero_utils import get_libero_image, quat2axisangle\n",
    "def _obs_to_input(obs):\n",
    "    # remove the wrist image\n",
    "    return {\n",
    "        \"full_image\": get_libero_image(obs, 224),\n",
    "        \"state\": np.concatenate([\n",
    "            obs[\"robot0_eef_pos\"],\n",
    "            quat2axisangle(obs[\"robot0_eef_quat\"]),\n",
    "            obs[\"robot0_gripper_qpos\"]\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168eaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def center_crop_image(image: Image.Image) -> Image.Image:\n",
    "\n",
    "    crop_scale = 0.9\n",
    "    orig_w, orig_h = image.size\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    crop_h = int(orig_h * crop_scale)\n",
    "    crop_w = int(orig_w * crop_scale)\n",
    "    image_tensor = F.center_crop(image_tensor, (crop_h, crop_w))\n",
    "    image_tensor = F.resize(image_tensor, (orig_h, orig_w))\n",
    "    final_image = F.to_pil_image(image_tensor)\n",
    "    \n",
    "    final_image = final_image.convert(\"RGB\")\n",
    "    return final_image\n",
    "\n",
    "def process_input(inputs:list, task_descriptions:list, config):\n",
    "    \n",
    "    batchdata = {\"input_ids\":[],\"attention_mask\":[],\"pixel_values\":[]}  \n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i]\n",
    "        task_description = task_descriptions[i]\n",
    "        \n",
    "        image = Image.fromarray(input[\"full_image\"]).convert(\"RGB\")\n",
    "        if config[\"center_crop\"]:\n",
    "            image = center_crop_image(image)\n",
    "        prompt = f\"In: What action should the robot take to {task_description.lower()}?\\nOut:\"\n",
    "        batch_feature  = processor(prompt, image)\n",
    "        \n",
    "        if \"wrist_image\" in input.keys():\n",
    "            wrist_image = Image.fromarray(input[\"wrist_image\"]).convert(\"RGB\")\n",
    "            if config[\"center_crop\"]:\n",
    "                wrist_image = center_crop_image(wrist_image)\n",
    "            wrist_batch_feature = processor(prompt, wrist_image)\n",
    "            primary_pixel_values = batch_feature[\"pixel_values\"]\n",
    "            batch_feature[\"pixel_values\"] = torch.cat([primary_pixel_values] + [wrist_batch_feature[\"pixel_values\"]], dim=1)\n",
    "            \n",
    "        input_ids = batch_feature[\"input_ids\"]\n",
    "        attention_mask = batch_feature[\"attention_mask\"]\n",
    "        pixel_values = batch_feature[\"pixel_values\"]\n",
    "        \n",
    "        if not torch.all(input_ids[:, -1] == 29871):\n",
    "            input_ids = torch.cat(\n",
    "                (input_ids, torch.unsqueeze(torch.Tensor([29871]).long(), dim=0).to(input_ids.device)), dim=1\n",
    "            )\n",
    "            attention_mask = torch.cat(\n",
    "                (attention_mask, torch.unsqueeze(torch.Tensor([True]).bool(), dim=0).to(attention_mask.device)), dim=1\n",
    "            )\n",
    "        \n",
    "        batchdata[\"input_ids\"].append(input_ids)    \n",
    "        batchdata[\"attention_mask\"].append(attention_mask)    \n",
    "        batchdata[\"pixel_values\"].append(pixel_values)    \n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda') \n",
    "    \n",
    "    batchdata[\"input_ids\"] = [x.transpose(0, 1) for x in batchdata[\"input_ids\"]]\n",
    "    batchdata[\"attention_mask\"] = [x.transpose(0, 1) for x in batchdata[\"attention_mask\"]]\n",
    "    batchdata[\"input_ids\"] = pad_sequence(batchdata[\"input_ids\"], batch_first=True, padding_value=processor.tokenizer.pad_token_id).squeeze(-1).to(device)\n",
    "    batchdata[\"attention_mask\"] = pad_sequence(batchdata[\"attention_mask\"], batch_first=True, padding_value=0).squeeze(-1).to(device)\n",
    "    \n",
    "    padding_mask = batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id)\n",
    "    assert  torch.all(padding_mask==batchdata[\"attention_mask\"].ne(0))\n",
    "    padding_mask = ~padding_mask\n",
    "    padding_mask = padding_mask.int() \n",
    "    sorted_indices = torch.argsort(padding_mask, dim=1, descending=True, stable=True)\n",
    "    batchdata[\"input_ids\"] = torch.gather(batchdata[\"input_ids\"], 1, sorted_indices)\n",
    "    batchdata[\"attention_mask\"] = torch.gather(batchdata[\"attention_mask\"], 1, sorted_indices)\n",
    "    \n",
    "    \n",
    "    batchdata[\"pixel_values\"] = torch.cat(batchdata[\"pixel_values\"] , dim=0).to(device)\n",
    "    assert torch.all(batchdata[\"attention_mask\"].ne(0) == batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id))\n",
    "\n",
    "    return batchdata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346164af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.device' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m actor_module = actor_module.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m actor_module.eval()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mactor_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'torch.device' object is not callable"
     ]
    }
   ],
   "source": [
    "actor_module = actor_module.to('cuda')\n",
    "actor_module.eval()\n",
    "actor_module.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8daf18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_SAMPLE = True\n",
    "TEMP = 1.6\n",
    "UNNORM_KEY = \"libero_10\"\n",
    "UNNORM_KEY = f\"{UNNORM_KEY}_no_noops\"\n",
    "MAX_PROMPT_LENGTH = 512\n",
    "def pad_sequence_to_length(tensors, max_seq_len, pad_token_id, left_pad=False):\n",
    "    \"\"\"\n",
    "    pad a 2D tensors (e.g. responses, logprobs) in the last dim to max_seq_length.\n",
    "    input shape: [bs, seq_length]\n",
    "    output shape: [bs, max_seq_length]\n",
    "    (0, max_seq_len - tensors.shape[-1]) means right pad to max_seq_length and no left pad\n",
    "    \"\"\"\n",
    "    if tensors.shape[-1] >= max_seq_len:\n",
    "        return tensors\n",
    "    pad_tuple = (max_seq_len - tensors.shape[-1], 0) if left_pad else (0, max_seq_len - tensors.shape[-1])\n",
    "    return torch.nn.functional.pad(tensors, pad_tuple, 'constant', pad_token_id)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _generate_one_step(prompts: dict):\n",
    "    idx = prompts['input_ids']  # (bs, prompt_length)\n",
    "    attention_mask = prompts['attention_mask']  # left-padded attention_mask\n",
    "    pixel_values = prompts[\"pixel_values\"]\n",
    "\n",
    "\n",
    "\n",
    "    # make sampling args can be overriden by inputs\n",
    "    do_sample = prompts.get('do_sample', DO_SAMPLE)\n",
    "\n",
    "\n",
    "    temperature = prompts.get('temperature', TEMP)\n",
    "\n",
    "    #generation_config = GenerationConfig(temperature=temperature, top_p=top_p, top_k=top_k)\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        actions, response = actor_module.generate_action_verl(\n",
    "            input_ids=idx,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            padding_idx = processor.tokenizer.pad_token_id,\n",
    "            do_sample=do_sample,\n",
    "            unnorm_key= UNNORM_KEY,\n",
    "            temperature=temperature, )\n",
    "    \n",
    "    \n",
    "    assert processor.tokenizer.pad_token_id is not None\n",
    "\n",
    "    assert idx.ndim == 2\n",
    "    idx = pad_sequence_to_length(idx,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=processor.tokenizer.pad_token_id,left_pad=True)\n",
    "    \n",
    "    assert attention_mask.ndim == 2\n",
    "    attention_mask = pad_sequence_to_length(attention_mask,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=0,left_pad=True)\n",
    "    \n",
    "    \n",
    "    assert idx.device.type == 'cuda'\n",
    "    assert response.device.type == 'cuda'\n",
    "    #assert seq.device.type == 'cuda'\n",
    "    assert attention_mask.device.type == 'cuda'\n",
    "    assert pixel_values.device.type == 'cuda'\n",
    "    batch ={\n",
    "            'responses': response,\n",
    "            'input_ids': idx,\n",
    "            'attention_mask': attention_mask,\n",
    "            \"pixel_values\":pixel_values,\n",
    "            \"action\":actions,\n",
    "        }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd03b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /file_system/cyk/vla_mix/LIBERO/libero/libero/../datasets does not exist!\n",
      "Initial data: {'type': 'init', 'obs': OrderedDict([('robot0_joint_pos', array([ 0.00656868, -0.18201341,  0.01442465, -2.47342319,  0.00391101,\n",
      "        2.23496506,  0.80100066])), ('robot0_joint_pos_cos', array([ 0.99997843,  0.98348124,  0.99989597, -0.78495709,  0.99999235,\n",
      "       -0.61640478,  0.69598853])), ('robot0_joint_pos_sin', array([ 0.00656864, -0.18101009,  0.01442415, -0.61955014,  0.003911  ,\n",
      "        0.78742946,  0.7180529 ])), ('robot0_joint_vel', array([-2.01874574e-03,  1.03248609e-05,  7.92422787e-06, -2.52319442e-05,\n",
      "        5.34783824e-03, -4.40832558e-05,  1.03695310e-02])), ('robot0_eef_pos', array([-0.21680813,  0.00942231,  1.17117443])), ('robot0_eef_quat', array([ 9.99600340e-01,  1.55205698e-03, -2.82250684e-02,  3.09803869e-04])), ('robot0_gripper_qpos', array([ 0.03872147, -0.03872411])), ('robot0_gripper_qvel', array([ 0.00326971, -0.00325662])), ('agentview_image', array([[[180, 165, 147],\n",
      "        [180, 164, 146],\n",
      "        [180, 164, 146],\n",
      "        ...,\n",
      "        [197, 180, 164],\n",
      "        [194, 177, 161],\n",
      "        [199, 182, 166]],\n",
      "\n",
      "       [[181, 166, 148],\n",
      "        [180, 164, 146],\n",
      "        [180, 163, 145],\n",
      "        ...,\n",
      "        [196, 179, 163],\n",
      "        [195, 178, 162],\n",
      "        [202, 185, 169]],\n",
      "\n",
      "       [[179, 164, 146],\n",
      "        [179, 163, 145],\n",
      "        [179, 163, 145],\n",
      "        ...,\n",
      "        [195, 178, 162],\n",
      "        [196, 179, 163],\n",
      "        [201, 184, 168]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[109, 107, 103],\n",
      "        [110, 108, 104],\n",
      "        [110, 108, 104],\n",
      "        ...,\n",
      "        [111, 109, 105],\n",
      "        [111, 109, 105],\n",
      "        [110, 109, 105]],\n",
      "\n",
      "       [[109, 107, 104],\n",
      "        [110, 107, 104],\n",
      "        [109, 107, 104],\n",
      "        ...,\n",
      "        [111, 109, 106],\n",
      "        [110, 109, 106],\n",
      "        [110, 108, 105]],\n",
      "\n",
      "       [[110, 108, 105],\n",
      "        [110, 108, 104],\n",
      "        [109, 107, 103],\n",
      "        ...,\n",
      "        [111, 108, 105],\n",
      "        [110, 108, 104],\n",
      "        [110, 108, 104]]], dtype=uint8)), ('robot0_eye_in_hand_image', array([[[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       [[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       [[ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        [ 53,  53,  53],\n",
      "        ...,\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52],\n",
      "        [ 52,  52,  52]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[201, 184, 164],\n",
      "        [202, 185, 165],\n",
      "        [204, 186, 167],\n",
      "        ...,\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10]],\n",
      "\n",
      "       [[201, 184, 165],\n",
      "        [202, 185, 165],\n",
      "        [204, 185, 167],\n",
      "        ...,\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10]],\n",
      "\n",
      "       [[203, 186, 166],\n",
      "        [201, 184, 164],\n",
      "        [204, 185, 167],\n",
      "        ...,\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10],\n",
      "        [ 13,  11,  10]]], dtype=uint8)), ('akita_black_bowl_1_pos', array([-0.08704032,  0.00426529,  0.89840386])), ('akita_black_bowl_1_quat', array([-2.77495335e-05,  3.33602362e-06,  7.07106779e-01,  7.07106783e-01])), ('akita_black_bowl_1_to_robot0_eef_pos', array([0.14493654, 0.00541687, 0.26501718])), ('akita_black_bowl_1_to_robot0_eef_quat', array([ 0.70792174, -0.70572597, -0.02017383,  0.01976681], dtype=float32)), ('cream_cheese_1_pos', array([-0.04434667,  0.13450387,  0.90890689])), ('cream_cheese_1_quat', array([-3.91694273e-18,  2.00015907e-17,  1.00000000e+00,  4.70730933e-26])), ('cream_cheese_1_to_robot0_eef_pos', array([ 0.18737114, -0.12468226,  0.25202978])), ('cream_cheese_1_to_robot0_eef_quat', array([ 1.5520573e-03, -9.9960017e-01, -3.0980134e-04,  2.8225062e-02],\n",
      "      dtype=float32)), ('wine_bottle_1_pos', array([-0.21042988, -0.05237711,  0.89886068])), ('wine_bottle_1_quat', array([-1.24479033e-05,  7.78166483e-07,  1.00000000e+00,  1.11108705e-08])), ('wine_bottle_1_to_robot0_eef_pos', array([0.02154364, 0.06167421, 0.27156359])), ('wine_bottle_1_to_robot0_eef_quat', array([ 1.5520941e-03, -9.9960005e-01, -3.0900585e-04,  2.8237507e-02],\n",
      "      dtype=float32)), ('plate_1_pos', array([ 0.03914755, -0.01717282,  0.90249957])), ('plate_1_quat', array([-2.66054380e-05,  1.20592137e-05,  7.07106753e-01,  7.07106809e-01])), ('plate_1_to_robot0_eef_pos', array([0.2706255 , 0.02725081, 0.25382283])), ('plate_1_to_robot0_eef_quat', array([ 0.7079219 , -0.70572597, -0.0201651 ,  0.01976565], dtype=float32)), ('robot0_proprio-state', array([ 6.56868490e-03, -1.82013411e-01,  1.44246491e-02, -2.47342319e+00,\n",
      "        3.91100754e-03,  2.23496506e+00,  8.01000659e-01,  9.99978426e-01,\n",
      "        9.83481239e-01,  9.99895967e-01, -7.84957087e-01,  9.99992352e-01,\n",
      "       -6.16404779e-01,  6.95988532e-01,  6.56863766e-03, -1.81010091e-01,\n",
      "        1.44241489e-02, -6.19550136e-01,  3.91099757e-03,  7.87429457e-01,\n",
      "        7.18052898e-01, -2.01874574e-03,  1.03248609e-05,  7.92422787e-06,\n",
      "       -2.52319442e-05,  5.34783824e-03, -4.40832558e-05,  1.03695310e-02,\n",
      "       -2.16808132e-01,  9.42231220e-03,  1.17117443e+00,  9.99600340e-01,\n",
      "        1.55205698e-03, -2.82250684e-02,  3.09803869e-04,  3.87214714e-02,\n",
      "       -3.87241149e-02,  3.26971500e-03, -3.25662136e-03])), ('object-state', array([-8.70403241e-02,  4.26528982e-03,  8.98403857e-01, -2.77495335e-05,\n",
      "        3.33602362e-06,  7.07106779e-01,  7.07106783e-01,  1.44936544e-01,\n",
      "        5.41687499e-03,  2.65017177e-01,  7.07921743e-01, -7.05725968e-01,\n",
      "       -2.01738253e-02,  1.97668057e-02, -4.43466728e-02,  1.34503873e-01,\n",
      "        9.08906885e-01, -3.91694273e-18,  2.00015907e-17,  1.00000000e+00,\n",
      "        4.70730933e-26,  1.87371138e-01, -1.24682258e-01,  2.52029785e-01,\n",
      "        1.55205734e-03, -9.99600172e-01, -3.09801340e-04,  2.82250624e-02,\n",
      "       -2.10429881e-01, -5.23771064e-02,  8.98860678e-01, -1.24479033e-05,\n",
      "        7.78166483e-07,  1.00000000e+00,  1.11108705e-08,  2.15436446e-02,\n",
      "        6.16742121e-02,  2.71563594e-01,  1.55209412e-03, -9.99600053e-01,\n",
      "       -3.09005845e-04,  2.82375067e-02,  3.91475507e-02, -1.71728248e-02,\n",
      "        9.02499567e-01, -2.66054380e-05,  1.20592137e-05,  7.07106753e-01,\n",
      "        7.07106809e-01,  2.70625502e-01,  2.72508130e-02,  2.53822831e-01,\n",
      "        7.07921922e-01, -7.05725968e-01, -2.01651007e-02,  1.97656471e-02]))]), 'task_description': 'open the middle drawer of the cabinet', 'valid_images': [array([[[110, 108, 104],\n",
      "        [110, 108, 104],\n",
      "        [111, 108, 105],\n",
      "        ...,\n",
      "        [109, 107, 103],\n",
      "        [110, 108, 104],\n",
      "        [110, 108, 105]],\n",
      "\n",
      "       [[110, 108, 105],\n",
      "        [110, 109, 106],\n",
      "        [111, 109, 106],\n",
      "        ...,\n",
      "        [109, 107, 104],\n",
      "        [110, 107, 104],\n",
      "        [109, 107, 104]],\n",
      "\n",
      "       [[110, 109, 105],\n",
      "        [111, 109, 105],\n",
      "        [111, 109, 105],\n",
      "        ...,\n",
      "        [110, 108, 104],\n",
      "        [110, 108, 104],\n",
      "        [109, 107, 103]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[201, 184, 168],\n",
      "        [196, 179, 163],\n",
      "        [195, 178, 162],\n",
      "        ...,\n",
      "        [179, 163, 145],\n",
      "        [179, 163, 145],\n",
      "        [179, 164, 146]],\n",
      "\n",
      "       [[202, 185, 169],\n",
      "        [195, 178, 162],\n",
      "        [196, 179, 163],\n",
      "        ...,\n",
      "        [180, 163, 145],\n",
      "        [180, 164, 146],\n",
      "        [181, 166, 148]],\n",
      "\n",
      "       [[199, 182, 166],\n",
      "        [194, 177, 161],\n",
      "        [197, 180, 164],\n",
      "        ...,\n",
      "        [180, 164, 146],\n",
      "        [180, 164, 146],\n",
      "        [180, 165, 147]]], dtype=uint8)], 'task_file_name': 'libero_goal_task_0_trial_0', 'active': True, 'complete': False, 'finish_step': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/file_system/cyk/vla_mix/test_rollout/.venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  return Image.fromarray(npimg, mode=mode)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import torch.cuda.profiler as profiler\n",
    "\n",
    "config = {\n",
    "    \"center_crop\": True,\n",
    "    \"num_steps_wait\": 10\n",
    "}\n",
    "\n",
    "\n",
    "# max_steps = 200\n",
    "max_steps = 512\n",
    "action_chunks_len = 8\n",
    "with torch.profiler.profile(\n",
    "            activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "            profile_memory=True,  # 内存数据采集的开关\n",
    "            record_shapes=True,  # 算子input shape信息采集的开关\n",
    "            with_stack=True,\n",
    "            with_flops=True,\n",
    "            with_modules=True,\n",
    "            schedule=torch.profiler.schedule(wait=10, warmup=1, active=3, repeat=2),\n",
    "            on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./traces\")\n",
    "    ) as prof:\n",
    "    libero_env = LiberoEnv(task_name=\"libero_goal\", task_id=0, trial_id=0, is_valid=True, max_steps=50, config=config)\n",
    "    valid_video = defaultdict(list)\n",
    "    vla_history = []\n",
    "    init_data = libero_env.get_initial_state()\n",
    "    print(\"Initial data:\", init_data)\n",
    "    task_descriptions = [init_data['task_description']]\n",
    "\n",
    "    valid_video[init_data['task_file_name']].extend(init_data['valid_images'])\n",
    "    env_data = copy.deepcopy(init_data)\n",
    "    env_obs = env_data['obs']\n",
    "    for step in range(max_steps):\n",
    "        # print(\"Step:\", step)\n",
    "        prof.step()\n",
    "        inputs = [_obs_to_input(env_obs)]\n",
    "        vla_input = process_input(inputs, task_descriptions, config)\n",
    "        # vla_input.update(meta_info)\n",
    "        vla_output = _generate_one_step(vla_input)\n",
    "        actions = vla_output[\"action\"]\n",
    "        step_data = {\n",
    "            \"responses\": vla_output[\"responses\"],\n",
    "            \"input_ids\": vla_output[\"input_ids\"],\n",
    "            \"attention_mask\": vla_output[\"attention_mask\"],\n",
    "            \"pixel_values\": vla_output[\"pixel_values\"],\n",
    "            \"action\": actions,\n",
    "            \"step\": step\n",
    "        }\n",
    "        vla_history.append(step_data)\n",
    "        \n",
    "\n",
    "        result = libero_env.step(actions[0])\n",
    "        valid_video[init_data['task_file_name']].extend(result['valid_images'])\n",
    "        env_obs = result[\"obs\"]\n",
    "\n",
    "        step += action_chunks_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vla_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce27b667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['libero_goal_task_0_trial_0'])\n"
     ]
    }
   ],
   "source": [
    "print(valid_video.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e9072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import random\n",
    "def save_rollout_video(rollout_images, exp_name, task_name, step_idx, success ):\n",
    "    \"\"\"Saves an MP4 replay of an episode.\"\"\"\n",
    "    rollout_dir = f\"./rollouts/{exp_name}\" \n",
    "    os.makedirs(rollout_dir, exist_ok=True)\n",
    "    ran_id = random.randint(1, 10000)\n",
    "    #processed_task_description = task_description.lower().replace(\" \", \"_\").replace(\"\\n\", \"_\").replace(\".\", \"_\")[:50]\n",
    "    mp4_path = f\"{rollout_dir}/step={step_idx}--task={task_name}--success={success}--ran={ran_id}.mp4\"\n",
    "    video_writer = imageio.get_writer(mp4_path, fps=30)\n",
    "    for img in rollout_images:\n",
    "        video_writer.append_data(img)\n",
    "    video_writer.close()\n",
    "    print(f\"Saved rollout MP4 at path {mp4_path}\")\n",
    "    return mp4_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c04d77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rollout MP4 at path ./rollouts/0/step=0--task=libero_goal_task_0_trial_0--success=False--ran=2133.mp4\n"
     ]
    }
   ],
   "source": [
    "for task_file, images in valid_video.items():\n",
    "    # complete = any(r['complete'] for r in task_records if r['task_file_name'] == task_file)\n",
    "    complete = False\n",
    "    save_rollout_video(\n",
    "        images,\n",
    "        \"0\",\n",
    "        task_file,\n",
    "        0,\n",
    "        complete\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-rollout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
